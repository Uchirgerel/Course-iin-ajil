{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ug taamaglalt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP39H3Go48Es+a1cM7B+k+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uchirgerel/Course-iin-ajil/blob/master/Ug_taamaglalt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGMrRX2K7AGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ашигласан сангууд numpy , tensorflow , keras , nltk\n",
        "import numpy ,tensorflow, keras, nltk\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX80H6_o7JIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Хэрэгтэй сангууд\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6HR4XCo7LVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dbb5088-9906-4e7c-a21d-9234f9fedbc1"
      },
      "source": [
        "# Датагаа аван Корпусныхаа хэмжээ(урт)-г авах\n",
        "path = '/content/data.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus urt:', len(text))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus urt: 11492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFzL4u9_7QUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ямар нэгэн тусгай тэмдэгтгүйгээр датаныхаа үг тус бүрийг салгаж авах\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)\n",
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGYc-QuD7YHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cc0a5978-97b7-4b60-cb6c-7a655e0476d1"
      },
      "source": [
        "# WORD_LENGTH - нь хэдэн үг урд орсон байна тэр тоогоор дараачийн үгийг\n",
        "# таамаглана. Үгийн урт нь дээд талдаа 5 байх бөгөөд prev_words гэх хоосон массив\n",
        "# үүсгэн түүндээ урд буй 5 үгээ хадгалах болно\n",
        "WORD_LENGTH = 5\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print(prev_words[0])\n",
        "print(next_words[0])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'to', 'fix', 'a', 'catalytic']\n",
            "converter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTc_nUX7bB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Энд 2 numpy массивийг зарлан X-д нь үгийн онцлог Y-д нь дарааллын үгийг \n",
        "# хадгалана. Тухайн үгийн байрлал нь 1-тэй тэнцэх үед X болон Y-ийг давталтанд\n",
        "# оруулна\n",
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "  for j, each_word in enumerate(each_words):\n",
        "    X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSeJ3E638nBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "bffb15ca-5706-4f08-f050-0a2bcf5c12db"
      },
      "source": [
        "# нэг дарааллын жишээг шалгаж буй нь\n",
        "print(X[0][0])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False  True False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfuvUJg99QxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 128 neuron-той бүрэн холбогдсон 1 давхаргатай softmax функц ашиглан model-ээ бэлдэв \n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBZP1wyG9Txt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af8b9089-846e-4282-ff4c-29f1514fd611"
      },
      "source": [
        "# RMSprop ашиглан 100 epoch явуулав\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=100, shuffle=True).history"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1369 samples, validate on 73 samples\n",
            "Epoch 1/100\n",
            "1369/1369 [==============================] - 1s 545us/step - loss: 4.4722 - accuracy: 0.1454 - val_loss: 7.0137 - val_accuracy: 0.0137\n",
            "Epoch 2/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 3.4050 - accuracy: 0.2615 - val_loss: 7.4313 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 2.5847 - accuracy: 0.3791 - val_loss: 8.4491 - val_accuracy: 0.0274\n",
            "Epoch 4/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 1.9973 - accuracy: 0.4916 - val_loss: 8.7599 - val_accuracy: 0.0137\n",
            "Epoch 5/100\n",
            "1369/1369 [==============================] - 0s 321us/step - loss: 1.4587 - accuracy: 0.6245 - val_loss: 9.6713 - val_accuracy: 0.0274\n",
            "Epoch 6/100\n",
            "1369/1369 [==============================] - 0s 353us/step - loss: 1.0005 - accuracy: 0.7538 - val_loss: 10.1585 - val_accuracy: 0.0411\n",
            "Epoch 7/100\n",
            "1369/1369 [==============================] - 0s 326us/step - loss: 0.7178 - accuracy: 0.8459 - val_loss: 10.3894 - val_accuracy: 0.0137\n",
            "Epoch 8/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.4888 - accuracy: 0.8948 - val_loss: 10.9612 - val_accuracy: 0.0274\n",
            "Epoch 9/100\n",
            "1369/1369 [==============================] - 0s 333us/step - loss: 0.3813 - accuracy: 0.9248 - val_loss: 11.5270 - val_accuracy: 0.0137\n",
            "Epoch 10/100\n",
            "1369/1369 [==============================] - 0s 338us/step - loss: 0.2941 - accuracy: 0.9372 - val_loss: 11.0946 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "1369/1369 [==============================] - 0s 321us/step - loss: 0.2608 - accuracy: 0.9394 - val_loss: 11.8567 - val_accuracy: 0.0274\n",
            "Epoch 12/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.1808 - accuracy: 0.9584 - val_loss: 12.1224 - val_accuracy: 0.0274\n",
            "Epoch 13/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.1528 - accuracy: 0.9591 - val_loss: 12.4804 - val_accuracy: 0.0274\n",
            "Epoch 14/100\n",
            "1369/1369 [==============================] - 0s 330us/step - loss: 0.1250 - accuracy: 0.9708 - val_loss: 12.7485 - val_accuracy: 0.0137\n",
            "Epoch 15/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.1004 - accuracy: 0.9737 - val_loss: 13.3681 - val_accuracy: 0.0274\n",
            "Epoch 16/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0888 - accuracy: 0.9781 - val_loss: 12.7271 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 13.7497 - val_accuracy: 0.0274\n",
            "Epoch 18/100\n",
            "1369/1369 [==============================] - 0s 323us/step - loss: 0.0583 - accuracy: 0.9832 - val_loss: 13.5541 - val_accuracy: 0.0137\n",
            "Epoch 19/100\n",
            "1369/1369 [==============================] - 0s 332us/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 13.0207 - val_accuracy: 0.0274\n",
            "Epoch 20/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 0.0890 - accuracy: 0.9781 - val_loss: 13.2773 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "1369/1369 [==============================] - 0s 332us/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 13.2136 - val_accuracy: 0.0137\n",
            "Epoch 22/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 13.7637 - val_accuracy: 0.0274\n",
            "Epoch 23/100\n",
            "1369/1369 [==============================] - 0s 334us/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 13.4166 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0732 - accuracy: 0.9803 - val_loss: 12.4939 - val_accuracy: 0.0137\n",
            "Epoch 25/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 13.2119 - val_accuracy: 0.0274\n",
            "Epoch 26/100\n",
            "1369/1369 [==============================] - 0s 333us/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 13.5612 - val_accuracy: 0.0274\n",
            "Epoch 27/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 13.5972 - val_accuracy: 0.0274\n",
            "Epoch 28/100\n",
            "1369/1369 [==============================] - 0s 347us/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 13.6447 - val_accuracy: 0.0137\n",
            "Epoch 29/100\n",
            "1369/1369 [==============================] - 0s 344us/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 13.0134 - val_accuracy: 0.0137\n",
            "Epoch 30/100\n",
            "1369/1369 [==============================] - 0s 339us/step - loss: 0.0422 - accuracy: 0.9898 - val_loss: 12.5591 - val_accuracy: 0.0274\n",
            "Epoch 31/100\n",
            "1369/1369 [==============================] - 0s 323us/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 13.0674 - val_accuracy: 0.0274\n",
            "Epoch 32/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 13.0997 - val_accuracy: 0.0137\n",
            "Epoch 33/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 13.6396 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 13.7955 - val_accuracy: 0.0137\n",
            "Epoch 35/100\n",
            "1369/1369 [==============================] - 0s 334us/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 13.7168 - val_accuracy: 0.0137\n",
            "Epoch 36/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 13.8419 - val_accuracy: 0.0137\n",
            "Epoch 37/100\n",
            "1369/1369 [==============================] - 0s 333us/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 13.2479 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 13.1053 - val_accuracy: 0.0137\n",
            "Epoch 39/100\n",
            "1369/1369 [==============================] - 0s 334us/step - loss: 0.0146 - accuracy: 0.9934 - val_loss: 12.8461 - val_accuracy: 0.0137\n",
            "Epoch 40/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0111 - accuracy: 0.9942 - val_loss: 13.4161 - val_accuracy: 0.0137\n",
            "Epoch 41/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0114 - accuracy: 0.9942 - val_loss: 13.5261 - val_accuracy: 0.0137\n",
            "Epoch 42/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 13.9813 - val_accuracy: 0.0137\n",
            "Epoch 43/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 13.8277 - val_accuracy: 0.0137\n",
            "Epoch 44/100\n",
            "1369/1369 [==============================] - 0s 331us/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 14.1617 - val_accuracy: 0.0137\n",
            "Epoch 45/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0528 - accuracy: 0.9847 - val_loss: 11.8534 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "1369/1369 [==============================] - 0s 330us/step - loss: 0.0215 - accuracy: 0.9912 - val_loss: 12.1290 - val_accuracy: 0.0137\n",
            "Epoch 47/100\n",
            "1369/1369 [==============================] - 0s 322us/step - loss: 0.0141 - accuracy: 0.9927 - val_loss: 12.2822 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 12.3980 - val_accuracy: 0.0137\n",
            "Epoch 49/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0105 - accuracy: 0.9949 - val_loss: 12.7262 - val_accuracy: 0.0137\n",
            "Epoch 50/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 12.9670 - val_accuracy: 0.0137\n",
            "Epoch 51/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0091 - accuracy: 0.9949 - val_loss: 13.2607 - val_accuracy: 0.0137\n",
            "Epoch 52/100\n",
            "1369/1369 [==============================] - 0s 330us/step - loss: 0.0115 - accuracy: 0.9934 - val_loss: 13.0246 - val_accuracy: 0.0137\n",
            "Epoch 53/100\n",
            "1369/1369 [==============================] - 0s 353us/step - loss: 0.0118 - accuracy: 0.9942 - val_loss: 14.0656 - val_accuracy: 0.0274\n",
            "Epoch 54/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0181 - accuracy: 0.9927 - val_loss: 12.7234 - val_accuracy: 0.0137\n",
            "Epoch 55/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0247 - accuracy: 0.9905 - val_loss: 12.6752 - val_accuracy: 0.0137\n",
            "Epoch 56/100\n",
            "1369/1369 [==============================] - 0s 320us/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 12.3415 - val_accuracy: 0.0137\n",
            "Epoch 57/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 12.6253 - val_accuracy: 0.0137\n",
            "Epoch 58/100\n",
            "1369/1369 [==============================] - 0s 322us/step - loss: 0.0102 - accuracy: 0.9949 - val_loss: 12.7752 - val_accuracy: 0.0137\n",
            "Epoch 59/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.0087 - accuracy: 0.9956 - val_loss: 13.0000 - val_accuracy: 0.0137\n",
            "Epoch 60/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0108 - accuracy: 0.9942 - val_loss: 13.1861 - val_accuracy: 0.0137\n",
            "Epoch 61/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0102 - accuracy: 0.9934 - val_loss: 13.4213 - val_accuracy: 0.0137\n",
            "Epoch 62/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.0097 - accuracy: 0.9942 - val_loss: 13.6872 - val_accuracy: 0.0137\n",
            "Epoch 63/100\n",
            "1369/1369 [==============================] - 0s 323us/step - loss: 0.0102 - accuracy: 0.9942 - val_loss: 13.9238 - val_accuracy: 0.0137\n",
            "Epoch 64/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 13.6997 - val_accuracy: 0.0137\n",
            "Epoch 65/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0275 - accuracy: 0.9883 - val_loss: 11.6840 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "1369/1369 [==============================] - 0s 326us/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 12.0188 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "1369/1369 [==============================] - 0s 326us/step - loss: 0.0123 - accuracy: 0.9934 - val_loss: 12.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "1369/1369 [==============================] - 0s 336us/step - loss: 0.0133 - accuracy: 0.9927 - val_loss: 12.1574 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0303 - accuracy: 0.9876 - val_loss: 11.9164 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0144 - accuracy: 0.9934 - val_loss: 11.9226 - val_accuracy: 0.0137\n",
            "Epoch 71/100\n",
            "1369/1369 [==============================] - 0s 336us/step - loss: 0.0095 - accuracy: 0.9942 - val_loss: 12.0939 - val_accuracy: 0.0137\n",
            "Epoch 72/100\n",
            "1369/1369 [==============================] - 0s 330us/step - loss: 0.0092 - accuracy: 0.9949 - val_loss: 12.3269 - val_accuracy: 0.0137\n",
            "Epoch 73/100\n",
            "1369/1369 [==============================] - 0s 335us/step - loss: 0.0098 - accuracy: 0.9942 - val_loss: 12.5065 - val_accuracy: 0.0137\n",
            "Epoch 74/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 0.0095 - accuracy: 0.9949 - val_loss: 12.7596 - val_accuracy: 0.0137\n",
            "Epoch 75/100\n",
            "1369/1369 [==============================] - 0s 337us/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 12.7773 - val_accuracy: 0.0137\n",
            "Epoch 76/100\n",
            "1369/1369 [==============================] - 0s 342us/step - loss: 0.0094 - accuracy: 0.9942 - val_loss: 13.2478 - val_accuracy: 0.0137\n",
            "Epoch 77/100\n",
            "1369/1369 [==============================] - 0s 331us/step - loss: 0.0100 - accuracy: 0.9949 - val_loss: 12.8984 - val_accuracy: 0.0137\n",
            "Epoch 78/100\n",
            "1369/1369 [==============================] - 0s 324us/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 11.7700 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "1369/1369 [==============================] - 0s 337us/step - loss: 0.0175 - accuracy: 0.9898 - val_loss: 11.8031 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "1369/1369 [==============================] - 0s 322us/step - loss: 0.0138 - accuracy: 0.9920 - val_loss: 12.0225 - val_accuracy: 0.0137\n",
            "Epoch 81/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0091 - accuracy: 0.9956 - val_loss: 12.1366 - val_accuracy: 0.0137\n",
            "Epoch 82/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 0.0091 - accuracy: 0.9956 - val_loss: 12.2717 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0090 - accuracy: 0.9927 - val_loss: 12.4098 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "1369/1369 [==============================] - 0s 330us/step - loss: 0.0089 - accuracy: 0.9949 - val_loss: 12.5930 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "1369/1369 [==============================] - 0s 329us/step - loss: 0.0087 - accuracy: 0.9934 - val_loss: 12.8014 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "1369/1369 [==============================] - 0s 326us/step - loss: 0.0087 - accuracy: 0.9949 - val_loss: 12.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "1369/1369 [==============================] - 0s 323us/step - loss: 0.0093 - accuracy: 0.9942 - val_loss: 13.0209 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0090 - accuracy: 0.9942 - val_loss: 13.1699 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0203 - accuracy: 0.9905 - val_loss: 12.3286 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "1369/1369 [==============================] - 0s 328us/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 12.5048 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "1369/1369 [==============================] - 0s 325us/step - loss: 0.0099 - accuracy: 0.9949 - val_loss: 12.5762 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "1369/1369 [==============================] - 0s 332us/step - loss: 0.0087 - accuracy: 0.9942 - val_loss: 12.6882 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0088 - accuracy: 0.9934 - val_loss: 12.7555 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "1369/1369 [==============================] - 0s 332us/step - loss: 0.0088 - accuracy: 0.9927 - val_loss: 12.8802 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "1369/1369 [==============================] - 0s 322us/step - loss: 0.0089 - accuracy: 0.9934 - val_loss: 12.9489 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0086 - accuracy: 0.9942 - val_loss: 13.2321 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "1369/1369 [==============================] - 0s 333us/step - loss: 0.0089 - accuracy: 0.9942 - val_loss: 13.1717 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "1369/1369 [==============================] - 0s 326us/step - loss: 0.0088 - accuracy: 0.9949 - val_loss: 13.4640 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "1369/1369 [==============================] - 0s 346us/step - loss: 0.0086 - accuracy: 0.9949 - val_loss: 13.2163 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "1369/1369 [==============================] - 0s 327us/step - loss: 0.0088 - accuracy: 0.9942 - val_loss: 13.4873 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quXovnbg9Zu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqvq294j9n1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Одоо таамаглах\n",
        "# Таамаглахдаа жижиг өгөгдөл өгөн түүгээрээ залан вектор болгож өгнө \n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "    return x\n",
        "    \n",
        "    prepare_input(\"It is not a lack\".lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIUYcp1t90p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Моделоо ашиглан таамаглахдаа Sample функцыг ашиглан хамгийн боломжит хувилбарыг олно \n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71lXRlol92yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict_completions функц моделыг ашиглаж үгсийг таамаглан буцаана \n",
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRJMPWe_94uU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "869cced8-c1db-4316-bfc1-3a50aaafaab2"
      },
      "source": [
        "q =  \"How to fix catalytic\"\n",
        "print(\"зөв өгүүлбэр: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Дараалал: \",seq)\n",
        "print(\"Дараагийн үгнүүд: \", predict_completions(seq, 5))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "зөв өгүүлбэр:  How to fix catalytic\n",
            "Дараалал:  how to fix catalytic\n",
            "how\n",
            "to\n",
            "fix\n",
            "catalytic\n",
            "Дараагийн үгнүүд:  ['contamination', 'consider', 'in', 'without', 'signs']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}